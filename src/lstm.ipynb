{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:00:46.185405Z",
     "start_time": "2024-06-10T02:00:33.778718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/camila/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/camila/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:01:08.973239Z",
     "start_time": "2024-06-10T02:01:08.194793Z"
    }
   },
   "id": "466ca01321fdf630"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   index     Artist                     Song Genre Language  \\\n0      0  12 stones            world so cold  Rock       en   \n1      1  12 stones                   broken  Rock       en   \n2      2  12 stones             3 leaf loser  Rock       en   \n3      3  12 stones  anthem for the underdog  Rock       en   \n4      4  12 stones               adrenaline  Rock       en   \n\n                                              Lyrics  \\\n0  It starts with pain, followed by hate\\nFueled ...   \n1  Freedom!\\nAlone again again alone\\nPatiently w...   \n2  Biting the hand that feeds you, lying to the v...   \n3  You say you know just who I am\\nBut you can't ...   \n4  My heart is beating faster can't control these...   \n\n                        Lyrics_Without_Special_Chars  lengths  \\\n0  It starts with pain followed by hate Fueled by...      332   \n1  Freedom Alone again again alone Patiently wait...      248   \n2  Biting the hand that feeds you lying to the vo...      142   \n3  You say you know just who I am But you cant im...      156   \n4  My heart is beating faster cant control these ...      337   \n\n                                      Limited_Lyrics  \\\n0  It starts with pain followed by hate Fueled by...   \n1  Freedom Alone again again alone Patiently wait...   \n2  Biting the hand that feeds you lying to the vo...   \n3  You say you know just who I am But you cant im...   \n4  My heart is beating faster cant control these ...   \n\n                            Lyrics_Without_Stopwords  \\\n0  starts pain followed hate Fueled endless quest...   \n1  Freedom Alone alone Patiently waiting phone Ho...   \n2  Biting hand feeds lying voice Inside reach beg...   \n3  say know cant imagine waits across line though...   \n4  heart beating faster cant control feelings any...   \n\n                             words_without_stopwords  \\\n0  [starts, pain, followed, hate, Fueled, endless...   \n1  [Freedom, Alone, alone, Patiently, waiting, ph...   \n2  [Biting, hand, feeds, lying, voice, Inside, re...   \n3  [say, know, cant, imagine, waits, across, line...   \n4  [heart, beating, faster, cant, control, feelin...   \n\n                         word_freq_without_stopwords  \\\n0  {'world': 12, 'hate': 6, 'dont': 6, 'believe':...   \n1  {'broken': 13, 'know': 9, 'need': 7, 'Im': 7, ...   \n2  {'life': 4, 'lesson': 4, 'take': 4, 'given': 4...   \n3  {'feeling': 4, 'cant': 3, 'Im': 3, 'thousand':...   \n4  {'heart': 9, 'cant': 8, 'control': 7, 'beating...   \n\n                         Lyrics_Without_Common_Words  \\\n0  starts pain followed hate Fueled endless quest...   \n1  Freedom Alone alone Patiently waiting phone Ho...   \n2  Biting hand feeds lying voice Inside reach beg...   \n3  imagine waits across line thought still standi...   \n4  beating faster control feelings anymore Ive wa...   \n\n                          words_without_common_words  \\\n0  [starts, pain, followed, hate, Fueled, endless...   \n1  [Freedom, Alone, alone, Patiently, waiting, ph...   \n2  [Biting, hand, feeds, lying, voice, Inside, re...   \n3  [imagine, waits, across, line, thought, still,...   \n4  [beating, faster, control, feelings, anymore, ...   \n\n                      word_freq_without_common_words  Song_Length_T2  \n0  {'world': 12, 'hate': 6, 'believe': 6, 'cold':...             124  \n1  {'broken': 13, 'need': 7, 'Cause': 6, 'inside'...             100  \n2  {'life': 4, 'lesson': 4, 'take': 4, 'given': 4...              65  \n3  {'feeling': 4, 'thousand': 3, 'hearts': 3, 'fe...              49  \n4  {'control': 7, 'beating': 6, 'faster': 6, 'fee...             107  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Artist</th>\n      <th>Song</th>\n      <th>Genre</th>\n      <th>Language</th>\n      <th>Lyrics</th>\n      <th>Lyrics_Without_Special_Chars</th>\n      <th>lengths</th>\n      <th>Limited_Lyrics</th>\n      <th>Lyrics_Without_Stopwords</th>\n      <th>words_without_stopwords</th>\n      <th>word_freq_without_stopwords</th>\n      <th>Lyrics_Without_Common_Words</th>\n      <th>words_without_common_words</th>\n      <th>word_freq_without_common_words</th>\n      <th>Song_Length_T2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>12 stones</td>\n      <td>world so cold</td>\n      <td>Rock</td>\n      <td>en</td>\n      <td>It starts with pain, followed by hate\\nFueled ...</td>\n      <td>It starts with pain followed by hate Fueled by...</td>\n      <td>332</td>\n      <td>It starts with pain followed by hate Fueled by...</td>\n      <td>starts pain followed hate Fueled endless quest...</td>\n      <td>[starts, pain, followed, hate, Fueled, endless...</td>\n      <td>{'world': 12, 'hate': 6, 'dont': 6, 'believe':...</td>\n      <td>starts pain followed hate Fueled endless quest...</td>\n      <td>[starts, pain, followed, hate, Fueled, endless...</td>\n      <td>{'world': 12, 'hate': 6, 'believe': 6, 'cold':...</td>\n      <td>124</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>12 stones</td>\n      <td>broken</td>\n      <td>Rock</td>\n      <td>en</td>\n      <td>Freedom!\\nAlone again again alone\\nPatiently w...</td>\n      <td>Freedom Alone again again alone Patiently wait...</td>\n      <td>248</td>\n      <td>Freedom Alone again again alone Patiently wait...</td>\n      <td>Freedom Alone alone Patiently waiting phone Ho...</td>\n      <td>[Freedom, Alone, alone, Patiently, waiting, ph...</td>\n      <td>{'broken': 13, 'know': 9, 'need': 7, 'Im': 7, ...</td>\n      <td>Freedom Alone alone Patiently waiting phone Ho...</td>\n      <td>[Freedom, Alone, alone, Patiently, waiting, ph...</td>\n      <td>{'broken': 13, 'need': 7, 'Cause': 6, 'inside'...</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>12 stones</td>\n      <td>3 leaf loser</td>\n      <td>Rock</td>\n      <td>en</td>\n      <td>Biting the hand that feeds you, lying to the v...</td>\n      <td>Biting the hand that feeds you lying to the vo...</td>\n      <td>142</td>\n      <td>Biting the hand that feeds you lying to the vo...</td>\n      <td>Biting hand feeds lying voice Inside reach beg...</td>\n      <td>[Biting, hand, feeds, lying, voice, Inside, re...</td>\n      <td>{'life': 4, 'lesson': 4, 'take': 4, 'given': 4...</td>\n      <td>Biting hand feeds lying voice Inside reach beg...</td>\n      <td>[Biting, hand, feeds, lying, voice, Inside, re...</td>\n      <td>{'life': 4, 'lesson': 4, 'take': 4, 'given': 4...</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12 stones</td>\n      <td>anthem for the underdog</td>\n      <td>Rock</td>\n      <td>en</td>\n      <td>You say you know just who I am\\nBut you can't ...</td>\n      <td>You say you know just who I am But you cant im...</td>\n      <td>156</td>\n      <td>You say you know just who I am But you cant im...</td>\n      <td>say know cant imagine waits across line though...</td>\n      <td>[say, know, cant, imagine, waits, across, line...</td>\n      <td>{'feeling': 4, 'cant': 3, 'Im': 3, 'thousand':...</td>\n      <td>imagine waits across line thought still standi...</td>\n      <td>[imagine, waits, across, line, thought, still,...</td>\n      <td>{'feeling': 4, 'thousand': 3, 'hearts': 3, 'fe...</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>12 stones</td>\n      <td>adrenaline</td>\n      <td>Rock</td>\n      <td>en</td>\n      <td>My heart is beating faster can't control these...</td>\n      <td>My heart is beating faster cant control these ...</td>\n      <td>337</td>\n      <td>My heart is beating faster cant control these ...</td>\n      <td>heart beating faster cant control feelings any...</td>\n      <td>[heart, beating, faster, cant, control, feelin...</td>\n      <td>{'heart': 9, 'cant': 8, 'control': 7, 'beating...</td>\n      <td>beating faster control feelings anymore Ive wa...</td>\n      <td>[beating, faster, control, feelings, anymore, ...</td>\n      <td>{'control': 7, 'beating': 6, 'faster': 6, 'fee...</td>\n      <td>107</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_words = 100\n",
    "frequency_threshold = 5000\n",
    "\n",
    "def remove_special_chars(raw_text):\n",
    "    mapping_table = str.maketrans({'\\n': ' ', '\\t': ' ', '\\x85': ' ', '\\xa0': ' ', '\\u2028': ' ', '\\u3000': ' '})\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', raw_text)\n",
    "    return text.translate(mapping_table)\n",
    "\n",
    "def format_training_data(data):\n",
    "    data = data[data['Language'] == 'en'].reset_index()\n",
    "    data['Lyrics_Without_Special_Chars'] = data['Lyrics'].apply(remove_special_chars)\n",
    "    data['lengths'] = data['Lyrics_Without_Special_Chars'].str.split(' ').str.len()\n",
    "    data = data[data['lengths'] >= min_words]\n",
    "    data['Limited_Lyrics'] = data['Lyrics_Without_Special_Chars'].str.split(' ').apply(lambda x: x[:min_words]).apply(lambda x: ' '.join(x))\n",
    "    data['Lyrics_Without_Stopwords'] = data['Lyrics_Without_Special_Chars'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "    data['words_without_stopwords'] = data['Lyrics_Without_Stopwords'].apply(lambda x: x.split())\n",
    "    data['word_freq_without_stopwords'] = data['words_without_stopwords'].apply(lambda x: dict(Counter(x).most_common(50)))\n",
    "    return data\n",
    "\n",
    "corpus = pd.read_csv('../csv/train_reduced.csv').dropna()\n",
    "train_data = format_training_data(corpus)\n",
    "\n",
    "\n",
    "\n",
    "# Gathering most common words\n",
    "dictionaries = []\n",
    "for genre in train_data['Genre'].unique():\n",
    "    combined_dict = Counter()\n",
    "    for words_dict in train_data[train_data['Genre'] == genre]['word_freq_without_stopwords']:\n",
    "        combined_dict += Counter(words_dict)\n",
    "\n",
    "    sorted_combined_dict = dict(sorted(combined_dict.most_common(30), key=lambda item: item[1], reverse=True))\n",
    "    dictionaries.append(sorted_combined_dict)\n",
    "\n",
    "common_words = Counter()\n",
    "for d in dictionaries:\n",
    "    common_words += Counter(d)\n",
    "most_common_words_df = pd.DataFrame(dict(sorted(common_words.most_common(30), key=lambda item: item[1], reverse=True)), index=[0]).T.reset_index().rename(columns={'index': 'word', 0: 'freq'})\n",
    "common_words_to_remove = list(most_common_words_df[most_common_words_df['freq'] >= frequency_threshold]['word'])\n",
    "\n",
    "train_data['Lyrics_Without_Common_Words'] = train_data['Lyrics_Without_Stopwords'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in common_words_to_remove]))\n",
    "train_data['words_without_common_words'] = train_data['Lyrics_Without_Common_Words'].apply(lambda x: x.split())\n",
    "train_data['word_freq_without_common_words'] = train_data['words_without_common_words'].apply(lambda x: dict(Counter(x).most_common(50)))\n",
    "train_data['Song_Length_T2'] = train_data['Lyrics_Without_Common_Words'].str.split(' ').str.len()\n",
    "\n",
    "train_data.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:13.078604Z",
     "start_time": "2024-06-10T02:03:49.100008Z"
    }
   },
   "id": "a3ce084f970bdfb9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics, genres):\n",
    "        self.lyrics = lyrics\n",
    "        self.genres = genres\n",
    "        self.vocab = set([word for lyrics in self.lyrics for word in lyrics.split()])\n",
    "        self.word_idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.genre_idx = {genre: idx for idx, genre in enumerate(set(self.genres))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lyrics)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lyrics = self.lyrics[idx]\n",
    "        genre = self.genres[idx]\n",
    "        lyrics_indices = [self.word_idx[word] for word in lyrics.split()]\n",
    "        genre_index = self.genre_idx[genre]\n",
    "        return torch.tensor(lyrics_indices), torch.tensor(genre_index)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:19.660474Z",
     "start_time": "2024-06-10T02:04:19.650050Z"
    }
   },
   "id": "34f3e1a443133320"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    lyrics, genres = zip(*data)\n",
    "    lyrics_indices = [torch.tensor(seq) for seq in lyrics]\n",
    "    genres = torch.tensor(genres)\n",
    "    lyrics_padded = pad_sequence(lyrics_indices, batch_first=True)\n",
    "    lengths = torch.tensor([len(seq) for seq in lyrics_indices])\n",
    "    return lyrics_padded, genres, lengths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:28.361823Z",
     "start_time": "2024-06-10T02:04:28.353753Z"
    }
   },
   "id": "34ac77e0cc5db0cd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:36.750161Z",
     "start_time": "2024-06-10T02:04:36.742410Z"
    }
   },
   "id": "22355579f9b19e69"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.Embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.LSTM = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=0.5)\n",
    "        self.Linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.Embedding(x)\n",
    "        packed_embedded = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
    "        pack_padded_output, _ = self.LSTM(packed_embedded)\n",
    "        pad_packed_output, _ = pad_packed_sequence(pack_padded_output, batch_first=True)\n",
    "        last_hidden_state = pad_packed_output[:, -1, :]\n",
    "        final_state = self.Linear(last_hidden_state)\n",
    "        output = self.Sigmoid(final_state)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:39.673303Z",
     "start_time": "2024-06-10T02:04:39.669833Z"
    }
   },
   "id": "7733031f671883ae"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "lstm_accuracies = []\n",
    "lstm_confusion_matrices = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:43.408041Z",
     "start_time": "2024-06-10T02:04:43.401878Z"
    }
   },
   "id": "ad5c8d7688b29751"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "lyrics_types = ['Lyrics', 'Lyrics_Without_Special_Chars', 'Lyrics_Without_Stopwords', 'Lyrics_Without_Common_Words', 'Limited_Lyrics']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:45.529353Z",
     "start_time": "2024-06-10T02:04:45.522511Z"
    }
   },
   "id": "9499d12b375bceac"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "songs_per_genre = 1890"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:04:47.250968Z",
     "start_time": "2024-06-10T02:04:47.244280Z"
    }
   },
   "id": "29017c858c3ea793"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Lyrics ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/var/folders/93/hty5syyx17sfgqtm2plpnw9w0000gn/T/ipykernel_23397/2544107450.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lyrics_indices = [torch.tensor(seq) for seq in lyrics]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 44\u001B[0m\n\u001B[1;32m     41\u001B[0m lengths \u001B[38;5;241m=\u001B[39m lengths\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m     43\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 44\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlyrics_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(logits, genres)\n\u001B[1;32m     47\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[8], line 12\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, x, lengths)\u001B[0m\n\u001B[1;32m     10\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mEmbedding(x)\n\u001B[1;32m     11\u001B[0m packed_embedded \u001B[38;5;241m=\u001B[39m pack_padded_sequence(embedded, lengths, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, enforce_sorted\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 12\u001B[0m pack_padded_output, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpacked_embedded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m pad_packed_output, _ \u001B[38;5;241m=\u001B[39m pad_packed_sequence(pack_padded_output, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     14\u001B[0m last_hidden_state \u001B[38;5;241m=\u001B[39m pad_packed_output[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:881\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    878\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers,\n\u001B[1;32m    879\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first)\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 881\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_sizes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    883\u001B[0m output \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    884\u001B[0m hidden \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;241m1\u001B[39m:]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for lyrics_type in lyrics_types:\n",
    "    print('----------',lyrics_type,'----------')\n",
    "    lyrics = list(train_data.groupby(['Genre']).head(songs_per_genre).reset_index()[lyrics_type])\n",
    "    genres = list(train_data.groupby(['Genre']).head(songs_per_genre).reset_index()['Genre'])\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset = LyricsDataset(lyrics, genres)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Define hyperparameters\n",
    "    vocab_size = len(dataset.vocab) + 1\n",
    "    embedding_dim = 200\n",
    "    hidden_dim = 512\n",
    "    output_dim = len(dataset.genre_idx)\n",
    "    num_epochs = 50\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    # Create the dataloaders with custom collate function\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Initialize the LSTM model\n",
    "    model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for lyrics_indices, genres, lengths in train_dataloader:\n",
    "            lyrics_indices = lyrics_indices.to(device)\n",
    "            genres = genres.to(device)\n",
    "            lengths = lengths.cpu()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(lyrics_indices, lengths)\n",
    "\n",
    "            loss = criterion(logits, genres)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            true_labels = []\n",
    "            predicted_labels = []\n",
    "            \n",
    "            for lyrics_indices, genres, lengths in test_dataloader:\n",
    "                lyrics_indices = lyrics_indices.to(device)\n",
    "                genres = genres.to(device)\n",
    "                lengths = lengths.cpu()\n",
    "\n",
    "                logits = model(lyrics_indices, lengths)\n",
    "                _, predictions = torch.max(logits, 1)\n",
    "\n",
    "                total_correct += (predictions == genres).sum().item()\n",
    "                total_samples += genres.size(0)\n",
    "                true_labels.extend(genres.cpu().numpy())\n",
    "                predicted_labels.extend(predictions.cpu().numpy())\n",
    "\n",
    "            accuracy = total_correct / total_samples\n",
    "            accuracies.append(accuracy)\n",
    "            print(f'Epoch {epoch + 1}: Accuracy = {accuracy:.4f}')\n",
    "\n",
    "    lstm_accuracies.append(accuracies)\n",
    "    confusion = confusion_matrix(true_labels, predicted_labels)\n",
    "    lstm_confusion_matrices.append(confusion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T02:08:00.298545Z",
     "start_time": "2024-06-10T02:04:51.650563Z"
    }
   },
   "id": "fc92acf8e954a287"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.arange(0,50)\n",
    "colours = ['blue', 'orange', 'green', 'purple', 'red']\n",
    "labels = ['lstm_lyrics', 'lstm_lyrics_without_special_chars', 'lstm_lyrics_without_stopwords', 'lstm_lyrics_without common words', 'lstm_limited_lyrics']\n",
    "for i in range(len(lstm_accuracies)):\n",
    "    plt.plot(X, lstm_accuracies[i], color=colours[i], label = labels[i])\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('LSTM Accuracies for all genres')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "419665f39b90ae7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lyrics\n",
    "disp = ConfusionMatrixDisplay(lstm_confusion_matrices[0])\n",
    "disp.plot()\n",
    "\n",
    "# Lyrics Without Special Chars\n",
    "disp = ConfusionMatrixDisplay(lstm_confusion_matrices[1])\n",
    "disp.plot()\n",
    "\n",
    "# Lyrics Without Stopwords\n",
    "disp = ConfusionMatrixDisplay(lstm_confusion_matrices[2])\n",
    "disp.plot()\n",
    "\n",
    "# Lyrics Without Common Words\n",
    "disp = ConfusionMatrixDisplay(lstm_confusion_matrices[3])\n",
    "disp.plot()\n",
    "\n",
    "# Limited Lyrics\n",
    "disp = ConfusionMatrixDisplay(lstm_confusion_matrices[3])\n",
    "disp.plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb9172cd7819c76a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
